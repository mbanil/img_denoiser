\documentclass[fleqn,10pt]{wlscirep}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{algorithm,algpseudocode}
\usepackage{mathtools}
\usepackage{epstopdf}
\epstopdfDeclareGraphicsRule{.tif}{png}{.png}{%
	convert #1 \OutputFile         
}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil} 
\title{Pattern matching based denoising for images with repeated sub structures.}

\author[1,*]{Alice Author}
\author[2]{Bob Author}
\author[1,2,+]{Christine Author}
\author[2,+]{Derek Author}
\affil[1]{Affiliation, department, city, postcode, country}
\affil[2]{Affiliation, department, city, postcode, country}

\affil[*]{corresponding.author@email.example}

\affil[+]{these authors contributed equally to this work}

%\keywords{Keyword1, Keyword2, Keyword3}

\begin{abstract}
	In electron microscopy, obtaining a noise-free image is often difficult while examining biological samples or delicate materials. Therefore, image denoising is an essential process for the analysis of such noisy images. State of the art image denoising methods are dominated by supervised Convolution Neural Network (CNN) based methods. However, if a noise-free ground truth is unavailable, it is not possible to use supervised CNNs. To address this problem, a denoising algorithm is proposed that uses re-occurring patterns in images. The proposed method does not require noise-free images for the denoising task. It is based on the idea that averaging images with the same signal having independent noise, suppresses the overall noise. In order to evaluate the performance of our method, the results are compared with other state of the art denoising methods that do not require a noise free image. Additionally, a confidence map is developed for evaluating the quality of denoising from the proposed method. Further, the run-time performance of the algorithm is analyzed and optimizations are made to improve the run-time efficiency. 
\end{abstract}
\begin{document}
	
	\flushbottom
	\maketitle
	% * <john.hammersley@gmail.com> 2015-02-09T12:07:31.197Z:
	%
	%  Click the title above to edit the author information and abstract
	%
	\thispagestyle{empty}
	
	\section*{Introduction}
	
	Transmission Electron Microscopy (TEM) imaging has been helpful to solve numerous scientific questions in life and material sciences \cite{CURRY200691}$^{,}$\cite{WANG2008395} . However, at times the noise in the acquired images corrupt the signal beyond a useful level. Noise in images can appear due to intrinsic reasons like problems in the sensors or the digital circuits, or due to external factors like the environment. Image denoising plays a vital role especially in suppressing microscopy image noise.
	
	The TEM imaging contrast is based on the interaction between specimen and a multi keV electron beam. While the optical resolution for modern TEM system can be below one angstrom, the high energy electrons often lead to a fast degradation of the sample. For such samples only few electrons can be used for imaging. This leads to a degradation of the image's effective resolution, thus making the image hard to interpret. Therefore, after image acquisition, numerical processing is required to enhance the image quality.
	
	To get the best image quality with minimum dose, various image denoising algorithms were proposed in the past. Conventional denoising methods\cite{bcm_nlm}$^{,}$ \cite{DBLP:journals/tip/BM3D} use only noisy images for the denoising task, whereas most modern methods involving a deep neural network\cite{zhang2018ffdnet}$^{,}$ \cite{zhang2017beyond}, require clean images as ground truths for training. Since clean electron microscopy images are not available in most cases, modern denoising methods that require clean images as ground truths cannot be used. However, there are also some deep neural network based methods that use noisy supervision\cite{DBLP:journals/corr/abs-1803-04189} and self supervision\cite{krull2019noise2void} . Although, conventional and self-supervised methods have shown success in denoising images, these methods improved the denoising quality only by a relatively small margin for images with repeated patterns. Hence, a new denoising algorithm is proposed and its results are analyzed and compared with the state-of-the-art methods showing significant gain in image quality. 
	
	
	\section*{Method}
	
	The proposed denoising algorithm identifies similar patches within the entire image and averages them to suppress the noise that is randomly distributed. Since the noise is assumed to be having zero mean, it cancels out when multiple patches are averaged. However the base signal remains the same throughout and averaging does not disrupt the signal. Hence combining different patches result in a denoised image, close to the actual signal value. 
	
	Let $x_{i}$ be the $i^{th}$ noisy patch, $k$ be the number of patches that are averaged, $s_i$, and $n_i$ be the signal and noise in the $i^{th}$ patch respectively. Then,
	\begin{equation}
		x_i = s_i + n_i
	\end{equation}
	Averaging over $k$ patches results in an expected value,
	\begin{equation}
		E[\frac{1}{k}\sum_{i}^{k}x_i ] = E[\frac{1}{k}\sum_{i}^{k}(s_i + n_i) ]
	\end{equation}
	Since the noise is expected to be having zero mean and the base signal is expected to be the same, this ideally means that,
	\begin{equation}
		E[\frac{1}{k}\sum_{i}^{k}x_i ] = s
	\end{equation}
	In addition, variance is 
	\begin{equation}
		Var[\frac{1}{k}\sum_{i}^{k}x_i ] = \frac{1}{k^2 -1} \sum_{i}^{k}Var(n_i)
	\end{equation}
	since $Var(s_i) = 0$ for all $i$. Hence averaging patches with the same signal suppresses noise.
	
	%The basic idea of the algorithm can be compared with the Single Particle Imaging \cite{bhushan_single_2017}, which is an image processing technique used to analyze low dose Transmission Electron Microscopy (TEM) images of identical but dose sensitive samples. Images of specimens obtained from TEM are often very noisy, and hence it is difficult to interpret the information contained in the image. Averaging several images of the same specimen can remove random noise and make the information more interpretable \cite{bhushan_single_2017}.
	
	%It can also be said that this algorithm is similar to the Non-Local Means \cite{bcm_nlm} algorithm in some aspects. In Non-Local Means, similar patches are found only from the immediate surroundings, where as the region of interest is not restricted in the proposed denoising algorithm. Increasing the search space in Non-Local Means has a massive impact on the computation speed. 
	
	\subsection*{Outline of the proposed algorithm}
	
	\begin{figure}
		\centering
		\includegraphics[scale=0.7]{./imgs/flowchart.png}
		\caption{Flowchart of the algorithm}
		\label{fig:flowchart}
	\end{figure} 
	
	The proposed algorithm groups similar patches at two levels. Cosine similarity is used to broadly group similar patches within an image and later, clustering is used to more finely group closely matching patches within the groups obtained during the first step. Flowchart of the algorithm is shown in figure \ref{fig:flowchart} and the two levels of the algorithm are represented by `classify' and `cluster' sections of the flowchart.
	
	Cosine similarity  measures similarities between two vectors\cite{alake_understanding_2021} by finding the cosine angle between them. If the vectors are in the same direction (i.e., similar), cosine similarity is maximum. It is mathematically represented as,
	\begin{equation}
		similarity = cos(\theta) = \frac{A\cdot B}{\|A\|\|B\|} = \frac{\sum_{i=1}^{n}A_i B_i}{\sqrt{\sum_{i=1}^{n}A_i^2}\sqrt{\sum_{i=1}^{n}B_i^2}}
	\end{equation}
	where $A$ and $B$ are two vectors, and $\theta$ is the angle between them. The cosine similarity value lies between -1 and 1. This is similar to the result obtained by template matching , which is represented in figure \ref{fig:template_matching}. An image, a template taken from the image, and the corresponding result can be seen in figure \ref{fig:template_matching}. The maximum value in the result which is marked in red, represents the template’s location in the image. It corresponds to the top-left corner of the template. Values close to the maximum represent the patches similar to the template. Hence, cosine similarity can be used to match patches with images, similar to template matching.
		
	\begin{figure}
		\centering
		\includegraphics[scale=0.8]{./imgs/template_matching.png}
		\caption[Template matching example]{Template matching example \footnote{\footnotemark} }
		\label{fig:template_matching}
	\end{figure} 
	
	\footnotetext{\url{https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_template.html}}
	
	
	
	The algorithm begins with the initialization of random patches of size $m*m$, which are used for matching other patches of size $m*m$ in the image. The patches that are used as templates for matching are referred to as \textit{reference patches}. One example for the initial choice of \textit{reference patches} can be seen in figure \ref{fig:initial_reference_patches}. 
	
	\begin{figure}
		\centering
		\includegraphics[scale=0.75]{./imgs/initial_reference_patches.png}
		\caption[Initial \textit{reference patches}]{Initial \textit{reference patches} (of size 46*46 pixels), taken from different regions of the input image}
		\label{fig:initial_reference_patches}
	\end{figure} 
	
	In the `classify'  section shown in figure \ref{fig:flowchart}, the patches at every position in the image are classified into different groups based on the \textit{reference patch} using cosine similarity. When cosine similarity is applied, each patch of size $m*m$ in the image is compared with all \textit{reference patch}. The result has values between -1 and 1 as the results are normalized. The location with a perfect match is represented by value 1. The patches similar to the \textit{reference patch} are represented by values close to 1. 
	
	Cosine similarity is carried out with all $n$ \textit{reference patches} and all the results are stacked into an array. From this array, the best fitting reference patch index at every position can be determined. Now, the patches in the image that are most similar to the \textit{reference patches} are identified and grouped together.   
	
	In the next step, the newly formed groups are deleted or split into finer groups based on the group size. The reasoning behind this process is that groups with few members contribute hardly to any denoising, while overly large groups might lead to a loss of detail.  Finally, for each group the old \textit{reference patch} is replaced by the average of all the members in that group. In the next iteration, cosine similarity and the classification steps repeat with these new \textit{reference patches}. We choose to terminate the “classify” section when the total number of reference patches in three consecutive iterations remains the same. Figure \ref{fig:final_reference_patches} shows the reference patches generated after 15 iterations. On comparing figure \ref{fig:initial_reference_patches} and figure \ref{fig:final_reference_patches}, one can observe that the noise in the final reference patches has been significantly suppressed.

	
	\begin{figure}
		\centering
		\includegraphics[scale=0.8]{./imgs/final_reference_patches.png}
		\caption{Final \textit{reference patches}}
		\label{fig:final_reference_patches}
	\end{figure} 
	
	If the final \textit{reference patches} are directly used for back plotting (i.e. to replace the patches in their corresponding groups), there would be still some artifacts present due of the following reasons. 
	
	
	\begin{itemize}
		\item There can be patches in a group that are less similar to the \textit{reference patch}. When these outliers are considered, \textbf{the mean deviates from the median signal value which is undesirable} \textit{\textbf{--> is this correct ???}} . 
		\item Cosine similarity is only sensitive to the structure for any two patches and ignores the offset (i.e. brightness). Therefore, back plotting might not recover local brightness variations.
	\end{itemize}
	
	These problems can be solved by averaging over a small group with very closely matched patches. To achieve this, clustering is applied within every group (represented by the final \textit{reference patch}) to create smaller subgroups. The number of clusters in a group can be adjusted by a user set parameter. In other words, the target signal-to-noise ratio can be adjusted by changing this parameter value. While previously the whole group was represented by a single \textit{reference patch}, it is now represented by centroids of the subgroups after clustering. Centroids are back plotted with a $2D$ Gaussian weighted average. These Gaussian weights smoothen the edges of the centroids, thus preventing artifacts in the reconstructed image. 
	
	A pseudo implementation of the algorithm is shown in the additional information section \ref{algorithm:denoising_algorithm}. The implementation of the denoising algorithm can be found on github\footnote{\url{https://github.com/mbanil/img-denoiser}}.
	
	\subsection*{Parameters of the algorithm and stability}
	
	For optimal performance, the algorithm requires a few parameters which the users can tune. The parameters include size of the features defined by patch size, position of the initial patches and depending on the amount of denoising desired, the upper and lower limit of the group size for cosine similarity classification. Finally, the group size for clustering can also be adjusted, which closely defines the desired signal to noise enhancement. If the user desires an improvement of approximately $N$, the average number of elements in a subgroup should be $N^2$ \cite{bcm_nlm}.
	
	\section*{Results}
	
	The proposed algorithm is mainly developed to denoise TEM images having repeated structures. The noisy image, the results from all the methods and their Fast Fourier transforms (FFT)\footnote{\url{https://numpy.org/doc/stable/reference/generated/numpy.fft.fft2.html}} can be seen in figure \ref{fig:comparison}. The FFT converts data from the spatial domain to the frequency domain. The signal corresponding to the low frequency components are represented at the center of the FFT and higher frequency components are present as we move away from the center. Noise corresponds to the high frequency components of the FFT and is present close to the edges.
	
	The following can be concluded from the figure \ref{fig:comparison}.
	\begin{itemize}
		\item The noisy image contains a lot of grainy structures which makes it hard to interpret the information. This is also reflected in the FFT, where clear structures are only visible close to the center.
		
		\item N2V\cite{krull2019noise2void} is a self supervised, deep learning based image denoising method. N2V was trained with the patches of the noisy image. The training was done with $64*64$ patches, 100 epochs and a neighboring radius of 5. 
		
		The results from N2V show a decently reconstructed circular structures and the noise in the black region of the image has been removed fairly well. However, the substructures have not been reconstructed well. The FFT shows enhanced structures at the center, whereas the boundary mostly looks dark representing the suppression of noise. 
		
		\item BM3D \cite{DBLP:journals/tip/BM3D} is one of the widely used classical denoising methods. BM3D uses collaborative filtering in the transform domain for denoising images and it is a non blind denoising method, which means that the standard deviation of the noise is required for denoising. The standard deviation was estimated with trial and error. The best results we obtained for a standard deviation of 0.06 for the normalized image.
		
		The results from BM3D are similar to that obtained from N2V. The denoising effect is visible but the images are still not very useful for further analysis. This is also supported by the FFT.
		
		\item Non Local Means (NLM) \cite{bcm_nlm} is a conventional image denoising method that finds similar patches of images within a region and averages them to suppress noise. An NLM implementation\footnote{\url{https://scikit-image.org/docs/stable/auto_examples/filters/plot_nonlocal_means.html}} with a patch size of $46*46$, a search area of $100*100$ and a cut off distance of 0.36 was used. 
		
		The result shows a good level of denoising. The circular structures and sub structures between them are visible fairly well. At most regions, the the level of noise suppression is good. But at some regions, the existence of noise can still be seen. The FFT also shows stronger white structures supporting the indicating the enhancement of image features. Overall, the results look good and more interpretable. 
		
		\item Results of our proposed denoising algorithm were obtained with a patch size of 46*46, a group size was between 5 and 100, and the clustering parameter equal to 2.7 were used. 
		
		From the denoised result, it can be observed that the quality of denoising is marginally better than that from NLM. The image noise levels are suppressed fairly well and the information from the image can be well interpreted. The sub structures between the circular structures are also better visible. From the FFT too, it can be seen that the white structures are more prominently visible. Some features can also be seen in the high frequency region which was previously not visible so well.
	\end{itemize}

	\begin{figure}
		\centering
		\includegraphics[scale=0.425]{./imgs/comparison.jpg}
		\caption{Comparison of results obtained from different methods}
		\label{fig:comparison}
	\end{figure}

	
	Apart from the qualitative improvement in the results, the proposed algorithm has a bigger advantage with regards to the computational time. The time complexity of the convolution operation is $O(m^2n^2)$, where $m*m$ is the size of the patch and $n*n$ is the size of the image, which is worse than the runtime of the template matching algorithm when $m$ is large. Complexity of the template matching algorithm is $O(n^2log(n^2))$ \cite{template_matching}, where $n*n$ is the image size. Since the convolution operation is widely used in convolutional neural networks, there are Python libraries that support GPU computation for performing the convolution operation. Running the computations on the GPU makes the algorithm much faster.
	
	The runtime of the proposed method for the images in figure \ref{fig:comparison} was 19.4 seconds, where as NLM, which was the closest to our results had a runtime of 171.4 seconds. The optimization in the runtime is particularly helpful when denoising image stacks from Transmission Electron Microscopy. The images in the stacks are often similar. In such cases, our algorithm not only matches the templates in the current image, but also the patches from other images in the stack. This significantly improves the quality of the results and with GPU computations, the computation speed is quite fast. For reference, the denoising of an image stack with 10 images of size 1024*1024 pixels took 281.8 seconds. The computations were carried out on a computer with 128 GB of RAM, Intel Xenon processor (16 CPUs), and Nvidia RTX6000 GPU.
	

	
	\subsection*{Comparison with sample images}
	
	Obtaining a noise free image is often very difficult when it comes to microscopy. For quantitative comparison of results, we have generated a noise free image (ground truth) artificially using python. The generated image tries to imitate the microscopy images which are best suited for our algorithm's application, i.e. images with similar patterns spread across the image. Noisy image is simulated by adding Poisson noise to the generated image. Different denoising methods have been applied on this noisy image and the Peak Signal to Noise Ratio (PSNR) and Structural Similarity Index Metric (SSIM) values of the denoised images have been found with respect to the ground truth. The ground truth, noisy image and the results from different methods can be seen in the figure \ref{fig:comparison_sample}. 
	
	The results from Non-Local Means show minimum improvement. This is because that this method requires similar image patches that are present close to each other, which is not always the case in the generated image. BM3D processes the image in the Fourier domain and hence suppressing the high frequency components. This results in the sharp features of the image being less prominent. N2V does a better denoising job which is reflected in it's PSNR value. However, on close inspection it can be observed that the high frequency components appear slightly blurred. This is where our method performs better. The pattern matching used to find similar pattern across the image ensures the correctness while preserving the sharpness of the image. This is also reflected in a higher SSIM value.
	
	It should be noted that PSNR is based on mean squared error and is a distortion based evaluation metric. In image restoration there is always a trade-off between the distortion and the perceptual quality of the restored image. Often it is not possible to achieve both simultaneously \cite{8578750}. In the figure \ref{fig:comparison_sample}, for our method even though we do not achieve the best PSNR value, we obtain the best results w.r.t SSIM which is a more perceptual metric \cite{8578750}.
	
	\begin{figure}
		\centering
		\includegraphics[scale=0.375]{./imgs/comparison_sample.jpg}
		\caption{Comparison of results obtained from different methods}
		\label{fig:comparison_sample}
	\end{figure}
	
	
	\subsection*{Confidence map}
	
	In the absence of a ground truth, it is difficult to identify artifacts in the denoised results. It is important to recognize these in order to determine if the denoised image is satisfactory. Since it is challenging to detect minute artifacts from FFT, a confidence map is developed. This confidence map is based on the variance within each cluster obtained after applying clustering. The variance should be small if the centroid is a good representation of its members. Also, a good centroid should not have any patterns in its variance. Patterns in the variance show that the centroid does not generalize it's members well. 
	
	The confidence map of the denoised image is calculated by combining the variances\cite{chan1982updating} for different centroids as they are back plotted. The overall variance map, i.e., the confidence map of a denoised image is as shown in figure \ref{fig:confidence_map}. This result has been produced for demonstration purpose with a very few initial \textit{reference patches} selected very close to each other. The bright regions in the confidence map correspond to the denoised image artifacts. For instance, a bright region can be seen in the confidence map at the top-right position. An artifact can be found by inspecting the same region on the denoised image. Similarly, irregularities in the black region on the left side of the denoised image can be recognized by the brighter regions of the confidence map.
	
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.7]{./imgs/confidence_map.png}
		\caption{Comparison of results obtained from different methods}
		\label{fig:confidence_map}
	\end{figure}
	
	\section*{Discussion}
	
	Denoising of the experimental images obtained from electron microscopy was performed by using different denoising methods - N2V, BM3D and NLM. A new denoising algorithm was developed which works based on similar patterns present in images and averaging them to suppress noise. This method successfully denoises images and also enhances minute structures which was not possible by the other methods. Working and time complexity of the proposed algorithm is analyzed and it's behavior under different circumstances is explained. The results of all the denoising methods are compared using FFT. Additionally, a confidence map is developed to evaluate the denoising results when ground truth data is absent. Quantitative comparison of the denoising results is done using an artificially generated image. The quantitative comparison demonstrates the ability of our proposed method to preserve high frequency components in images.  
	
	The algorithm is optimized to enhance the speed of computation by introducing cosine similarity instead of template matching. This helped in enhancing the run-time efficiency by a significant factor, for the hardware used in our experiments.
	
	\bibliography{sample}

	\section*{Acknowledgements (not compulsory)}
	
	Acknowledgements should be brief, and should not include thanks to anonymous referees and editors, or effusive comments. Grant or contribution numbers may be acknowledged.
	
	\section*{Author contributions statement}
	
	Must include all authors, identified by initials, for example:
	A.A. conceived the experiment(s),  A.A. and B.A. conducted the experiment(s), C.A. and D.A. analysed the results.  All authors reviewed the manuscript. 
	
	\section*{Additional information}
	
	\subsection*{Algorithm}
	\label{algorithms}
	
	\begin{algorithm}
		\caption{Denoising Algorithm}
		\label{algorithm:denoising_algorithm}
		\begin{algorithmic}[1]
			\State \textbf{Input}: Noisy image (\textit{imgs})
			\State \textbf{Result}: Denoised image
			\State set [\textit{templateSize, minGroupSize, maxGroupSize, clustParam, loopTermination}] ;
			\State \textit{refPatches} $\gets$ generate\_initial\_ref\_patches(\textit{imgs}, \textit{templateSize}) ;
			
			\For{\textit{loopTermination} $\geq$ 0 \textbf{or} (check if the number of \textit{refPatches} in the last two iterations has changed)}
			
			\State \textit{tmpMatchResult} $\gets$ [ ]	;		
			
			\For{\textit{img} in \textit{imgs}}
			\For{\textit{refPatch} in \textit{refPatches}}
			
			\State \textit{tmpMatchResult}.append(template\_matching(\textit{img}, \textit{refPatch})) ;
			
			\EndFor
			\EndFor
			
			\State \textit{maxValue} $\gets$ max(\textit{tmpMatchResult}, axis=2) ;
			\State \textit{refPatchIndex} $\gets$ `\textit{refPatches}' index at \textit{maxValue} ;
			\State [\textit{sorted\_maxValue, positionX, positionY}] $\gets$ sortWithIdx(\textit{maxValue}); 
			\State \textit{t} = \textit{templateSize} ;
			\State \textit{list[\textit{idx},\textit{posX},\textit{posY}]} = [ ];
			%%		\algstore{part1}
			%%\end{algorithmic}
			%%\end{algorithm}
			%%\begin{algorithm}
			%%	\begin{algorithmic}[1]
				%%		\algrestore{part1}
				
				\For{each \textit{s,posX,posY} in \textit{sorted\_maxValue, positionX, positionY}}
				\If{\textit{maxValue[posX,posY]} \textbf{not equal} 0}
				\State \textit{maxValue}[\textit{posX: posX}+($t/4$); \textit{posY: posY}+($t/4$)] $\gets$ 0 ;
				\State \textit{idx} $\gets$ \textit{refPatchIndex}[\textit{posX},\textit{posY}] ;
				\State \textit{list}.append([\textit{idx},\textit{posX},\textit{posY}]) ;
				\EndIf
				\EndFor
				
				\State [\textit{count,refPatchID}] $\gets$ count\_patches\_with\_same\_id(\textit{list});
				% \State \textit{max\_ind} = max(\textit{refPatchIndex}) ;
				
				\For{\textit{cnt,ID} in \textit{count,refPatchID}}
				\If{\textit{cnt} $\le$ \textit{minGroupSize}}
				\State \textit{list} $\gets$ delete(\textit{list}, \textit{ID});
				
				\ElsIf{\textit{cnt} $\ge$ \textit{maxGroupSize}}
				
				\State \textit{list} $\gets$ splitGroup(\textit{list}, \textit{ID}, \textit{maxGroupSize});
				
				%\For{\textit{l} in \textit{list}}
				%	\If{list[idx] == ind}
				%		\If{loopCounter == \textit{params}[\textit{maxGroupSize}]}
				%			\State \textit{loopCounter} = \textit{loopCounter} + 1
				%			\State \textit{list}[\textit{idx}] $\gets$ \textit{max\_ind}
				%			\State \textit{max\_ind} $\gets$\textit{ max\_ind} + 1
				%		\EndIf
				%	\EndIf
				%\EndFor
				
				\EndIf
				
				\EndFor
				
				\State \textit{refPatches} $\gets$ average\_patches\_with\_same\_id(\textit{list}) ;
				
				\State \textit{loopTermination} $\gets$ \textit{loopTermination}-1 ;
				\EndFor
				\State \textit{subGroup}[\textit{centroid, posX, posY}] = [ ];
				\For{\textit{refPatchID} in \textit{refPatches}}
				\State \textit{patches\_with\_sameRef} $\gets$ get\_patches\_with\_same\_id(\textit{list},\textit{refPatchID});
				\State \textit{numClusters} $\gets$ count(\textit{patches\_with\_sameRef})/\textit{clustParam} ;
				\State \textit{subGroup}.append(cluster(\textit{patches\_with\_sameRef, numClusters})) ;
				\EndFor
				\State \textit{gaussianWeight} $\gets$ createGaussianWeight();
				\State \textit{denoisedImg} $\gets$ backPlot(\textit{subGroup}, \textit{gaussianWeight});
			\end{algorithmic}
		\end{algorithm}
		
		\clearpage
		
		%\begin{algorithm}
		%	\caption{Algorithm for calculating variance}
		%	\label{algorithm:variance_algorithm}
		%	\begin{algorithmic}[1]
			%		\State \textit{weight} $\gets$ \textit{weightA} + \textit{weightB} ;
			%		\State \textit{delta} $\gets$ \textit{avgB} - \textit{avgA} ;
			%		\State \textit{M2} $\gets$ (\textit{M2\_A} + \textit{M2\_B} + $delta^2$ *  \textit{weightA} * \textit{weightB}) / n ;
			%		\State \textit{Var\_AB} = \textit{M2} / (\textit{n} - 1);
			%	\end{algorithmic}	
		%\end{algorithm}
		
	\end{document}